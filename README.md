# Adversarial-robustness-is-critical-for-safe-AI-deployment
adversarial robustness comparing ResNet-18 and Vision Transformer models on CIFAR-10. Using FGSM and PGD attacks at multiple perturbation levels (ε ∈ {2, 4, 8, 16}/255), 
 I demonstrated that ResNet-18 maintains 21.1% accuracy under strong PGD attacks at ε=8/255, while Vision Transformer accuracy drops to 1.8%, revealing critical architecture-dependent robustness trade-offs. 
 This research has been documented in a peer-reviewed paper with fully reproducible code, demonstrating my ability to design experiments independently. 
 implement adversarial methods, analyse results, and communicate findings at publication quality."
